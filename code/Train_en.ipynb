{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install jiwer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kangyi/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Libararies\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "import torch\n",
    "import evaluate\n",
    "from datasets import load_dataset, Audio\n",
    "from transformers import Wav2Vec2Processor\n",
    "from transformers import Wav2Vec2ForCTC\n",
    "from transformers import TrainingArguments\n",
    "from transformers import Trainer\n",
    "import tqdm as notebook_tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '/home/kangyi/Lyrics-audio-Alignment/dataset/songs_en'\n",
    "matedata_path = '/home/kangyi/Lyrics-audio-Alignment/dataset/output-en/metadata.csv'\n",
    "lang = \"en-US\"\n",
    "\n",
    "PRE_PROCESSED = True\n",
    "ORIGINAL_SR = 44100\n",
    "TARGET_SR = 16000"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Step 1: Load the CSV dataset\n",
    "###############################################################################\n",
    "\n",
    "dataset = load_dataset(\"csv\", data_files=matedata_path)[\"train\"]\n",
    "\n",
    "###############################################################################\n",
    "# Step 2: Split into train, validation, and test sets\n",
    "###############################################################################\n",
    "# Example: 80% train, 10% validation, 10% test\n",
    "\n",
    "# First create test split (10% of total)\n",
    "split_dataset = dataset.train_test_split(test_size=0.1, seed=42)\n",
    "train_val = split_dataset[\"train\"]\n",
    "test_dataset = split_dataset[\"test\"]\n",
    "\n",
    "# Now split the remaining 90% into 80% train and 10% val\n",
    "split_train_val = train_val.train_test_split(test_size=0.1111, seed=42)  # 0.1111 of 90% ~ 10%\n",
    "train_dataset = split_train_val[\"train\"]\n",
    "eval_dataset = split_train_val[\"test\"]\n",
    "\n",
    "print(\"Train samples:\", len(train_dataset))\n",
    "print(\"Validation samples:\", len(eval_dataset))\n",
    "print(\"Test samples:\", len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Step 3: Convert file_name column to Audio feature\n",
    "###############################################################################\n",
    "# This will decode and resample the audio at 16kHz on-the-fly\n",
    "train_dataset = train_dataset.cast_column(\"file_name\", Audio(sampling_rate=16000))\n",
    "eval_dataset = eval_dataset.cast_column(\"file_name\", Audio(sampling_rate=16000))\n",
    "test_dataset = test_dataset.cast_column(\"file_name\", Audio(sampling_rate=16000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Step 4: Load a Wav2Vec2 Processor\n",
    "###############################################################################\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "\n",
    "def normalize_text(text):\n",
    "    # Lowercase\n",
    "    if text == None:\n",
    "        return ''\n",
    "    text = text.lower()\n",
    "    # Remove punctuation except for apostrophes needed for words like \"don't\"\n",
    "    text = re.sub(r\"[^a-zA-Z0-9\\s']\", \"\", text)\n",
    "    text = text.strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=8):   0%|          | 0/17117 [00:00<?, ? examples/s]/home/kangyi/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/kangyi/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/kangyi/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/kangyi/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/kangyi/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/kangyi/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/kangyi/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/kangyi/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=8):   4%|▍         | 746/17117 [00:01<00:20, 800.21 examples/s]/home/kangyi/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/transformers/models/wav2vec2/feature_extraction_wav2vec2.py:98: RuntimeWarning: Mean of empty slice.\n",
      "  normed_input_values = [(x - x.mean()) / np.sqrt(x.var() + 1e-7) for x in input_values]\n",
      "/home/kangyi/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/numpy/_core/_methods.py:138: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/kangyi/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/transformers/models/wav2vec2/feature_extraction_wav2vec2.py:98: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  normed_input_values = [(x - x.mean()) / np.sqrt(x.var() + 1e-7) for x in input_values]\n",
      "/home/kangyi/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/numpy/_core/_methods.py:175: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/home/kangyi/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/numpy/_core/_methods.py:210: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "Map (num_proc=8):  15%|█▍        | 2527/17117 [00:02<00:05, 2436.37 examples/s]/home/kangyi/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/transformers/models/wav2vec2/feature_extraction_wav2vec2.py:98: RuntimeWarning: Mean of empty slice.\n",
      "  normed_input_values = [(x - x.mean()) / np.sqrt(x.var() + 1e-7) for x in input_values]\n",
      "/home/kangyi/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/numpy/_core/_methods.py:138: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/kangyi/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/transformers/models/wav2vec2/feature_extraction_wav2vec2.py:98: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  normed_input_values = [(x - x.mean()) / np.sqrt(x.var() + 1e-7) for x in input_values]\n",
      "Map (num_proc=8):  17%|█▋        | 2827/17117 [00:02<00:05, 2564.27 examples/s]/home/kangyi/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/numpy/_core/_methods.py:175: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/home/kangyi/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/numpy/_core/_methods.py:210: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "Map (num_proc=8):  18%|█▊        | 3114/17117 [00:02<00:05, 2616.47 examples/s]/home/kangyi/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/transformers/models/wav2vec2/feature_extraction_wav2vec2.py:98: RuntimeWarning: Mean of empty slice.\n",
      "  normed_input_values = [(x - x.mean()) / np.sqrt(x.var() + 1e-7) for x in input_values]\n",
      "/home/kangyi/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/numpy/_core/_methods.py:138: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/kangyi/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/transformers/models/wav2vec2/feature_extraction_wav2vec2.py:98: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  normed_input_values = [(x - x.mean()) / np.sqrt(x.var() + 1e-7) for x in input_values]\n",
      "/home/kangyi/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/numpy/_core/_methods.py:175: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/home/kangyi/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/numpy/_core/_methods.py:210: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "Map (num_proc=8):  20%|█▉        | 3421/17117 [00:02<00:05, 2717.79 examples/s]/home/kangyi/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/transformers/models/wav2vec2/feature_extraction_wav2vec2.py:98: RuntimeWarning: Mean of empty slice.\n",
      "  normed_input_values = [(x - x.mean()) / np.sqrt(x.var() + 1e-7) for x in input_values]\n",
      "/home/kangyi/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/numpy/_core/_methods.py:138: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/kangyi/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/transformers/models/wav2vec2/feature_extraction_wav2vec2.py:98: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  normed_input_values = [(x - x.mean()) / np.sqrt(x.var() + 1e-7) for x in input_values]\n",
      "/home/kangyi/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/numpy/_core/_methods.py:175: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/home/kangyi/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/numpy/_core/_methods.py:210: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "Map (num_proc=8):  25%|██▌       | 4359/17117 [00:02<00:04, 2944.89 examples/s]/home/kangyi/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/transformers/models/wav2vec2/feature_extraction_wav2vec2.py:98: RuntimeWarning: Mean of empty slice.\n",
      "  normed_input_values = [(x - x.mean()) / np.sqrt(x.var() + 1e-7) for x in input_values]\n",
      "/home/kangyi/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/numpy/_core/_methods.py:138: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/kangyi/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/transformers/models/wav2vec2/feature_extraction_wav2vec2.py:98: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  normed_input_values = [(x - x.mean()) / np.sqrt(x.var() + 1e-7) for x in input_values]\n",
      "/home/kangyi/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/numpy/_core/_methods.py:175: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/home/kangyi/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/numpy/_core/_methods.py:210: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "Map (num_proc=8):  27%|██▋       | 4670/17117 [00:03<00:04, 2958.51 examples/s]/home/kangyi/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/transformers/models/wav2vec2/feature_extraction_wav2vec2.py:98: RuntimeWarning: Mean of empty slice.\n",
      "  normed_input_values = [(x - x.mean()) / np.sqrt(x.var() + 1e-7) for x in input_values]\n",
      "/home/kangyi/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/numpy/_core/_methods.py:138: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/kangyi/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/transformers/models/wav2vec2/feature_extraction_wav2vec2.py:98: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  normed_input_values = [(x - x.mean()) / np.sqrt(x.var() + 1e-7) for x in input_values]\n",
      "/home/kangyi/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/numpy/_core/_methods.py:175: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/home/kangyi/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/numpy/_core/_methods.py:210: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "Map (num_proc=8):  31%|███       | 5288/17117 [00:03<00:04, 2949.19 examples/s]/home/kangyi/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/transformers/models/wav2vec2/feature_extraction_wav2vec2.py:98: RuntimeWarning: Mean of empty slice.\n",
      "  normed_input_values = [(x - x.mean()) / np.sqrt(x.var() + 1e-7) for x in input_values]\n",
      "/home/kangyi/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/numpy/_core/_methods.py:138: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/kangyi/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/transformers/models/wav2vec2/feature_extraction_wav2vec2.py:98: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  normed_input_values = [(x - x.mean()) / np.sqrt(x.var() + 1e-7) for x in input_values]\n",
      "/home/kangyi/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/numpy/_core/_methods.py:175: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/home/kangyi/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/numpy/_core/_methods.py:210: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "Map (num_proc=8): 100%|██████████| 17117/17117 [00:10<00:00, 1692.52 examples/s]\n",
      "Map (num_proc=8):   0%|          | 0/901 [00:00<?, ? examples/s]/home/kangyi/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=8):   0%|          | 1/901 [00:00<13:31,  1.11 examples/s]/home/kangyi/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/kangyi/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/kangyi/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/kangyi/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/kangyi/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/kangyi/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/kangyi/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/kangyi/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/transformers/models/wav2vec2/feature_extraction_wav2vec2.py:98: RuntimeWarning: Mean of empty slice.\n",
      "  normed_input_values = [(x - x.mean()) / np.sqrt(x.var() + 1e-7) for x in input_values]\n",
      "/home/kangyi/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/numpy/_core/_methods.py:138: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/kangyi/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/transformers/models/wav2vec2/feature_extraction_wav2vec2.py:98: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  normed_input_values = [(x - x.mean()) / np.sqrt(x.var() + 1e-7) for x in input_values]\n",
      "/home/kangyi/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/numpy/_core/_methods.py:175: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/home/kangyi/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/numpy/_core/_methods.py:210: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "Map (num_proc=8): 100%|██████████| 901/901 [00:01<00:00, 648.29 examples/s] \n",
      "Filter:   0%|          | 0/17117 [00:00<?, ? examples/s]/home/kangyi/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/transformers/models/wav2vec2/feature_extraction_wav2vec2.py:98: RuntimeWarning: Mean of empty slice.\n",
      "  normed_input_values = [(x - x.mean()) / np.sqrt(x.var() + 1e-7) for x in input_values]\n",
      "/home/kangyi/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/numpy/_core/_methods.py:138: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/kangyi/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/transformers/models/wav2vec2/feature_extraction_wav2vec2.py:98: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  normed_input_values = [(x - x.mean()) / np.sqrt(x.var() + 1e-7) for x in input_values]\n",
      "/home/kangyi/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/numpy/_core/_methods.py:175: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/home/kangyi/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/numpy/_core/_methods.py:210: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "Filter: 100%|██████████| 17117/17117 [02:13<00:00, 128.56 examples/s]\n",
      "Filter: 100%|██████████| 901/901 [00:06<00:00, 132.98 examples/s]\n"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "# Step 5: Preprocessing function\n",
    "###############################################################################\n",
    "def prepare_batch(batch):\n",
    "    audio = batch[\"file_name\"]\n",
    "    text = batch[\"text\"]\n",
    "    \n",
    "    # Normalize text if needed\n",
    "    text = normalize_text(text)\n",
    "\n",
    "    # Process audio\n",
    "    inputs = processor(\n",
    "        audio[\"array\"], \n",
    "        sampling_rate=audio[\"sampling_rate\"], \n",
    "        return_attention_mask=True,\n",
    "        padding=True  # Add padding here\n",
    "    )\n",
    "\n",
    "    # Encode labels (text)\n",
    "    with processor.as_target_processor():\n",
    "        labels = processor.tokenizer(\n",
    "        text, \n",
    "        padding=True,  # Padding for labels\n",
    "        truncation=True  # Optional: truncate labels if needed\n",
    "    ).input_ids\n",
    "\n",
    "    batch[\"input_values\"] = inputs[\"input_values\"][0]\n",
    "    batch[\"attention_mask\"] = inputs[\"attention_mask\"][0]\n",
    "    batch[\"labels\"] = labels\n",
    "    print(batch)\n",
    "    return batch\n",
    "\n",
    "# Apply the preprocessing to datasets\n",
    "train_dataset = train_dataset.map(prepare_batch, remove_columns=train_dataset.column_names)\n",
    "eval_dataset = eval_dataset.map(prepare_batch, remove_columns=eval_dataset.column_names)\n",
    "test_dataset = test_dataset.map(prepare_batch, remove_columns=test_dataset.column_names)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-large-960h-lv60-self and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/kangyi/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12822' max='12822' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12822/12822 59:19, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>4.976200</td>\n",
       "      <td>2.859481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>2.798400</td>\n",
       "      <td>2.561285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>2.536100</td>\n",
       "      <td>2.298822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>2.366700</td>\n",
       "      <td>2.132559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>2.242700</td>\n",
       "      <td>2.026144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>2.116500</td>\n",
       "      <td>1.931902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>2.007200</td>\n",
       "      <td>1.794211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>1.944600</td>\n",
       "      <td>1.695302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>1.809200</td>\n",
       "      <td>1.655811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>1.670200</td>\n",
       "      <td>1.580696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>1.582100</td>\n",
       "      <td>1.499800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>1.579500</td>\n",
       "      <td>1.467293</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kangyi/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/kangyi/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=12822, training_loss=2.2515898463395434, metrics={'train_runtime': 3560.4181, 'train_samples_per_second': 14.407, 'train_steps_per_second': 3.601, 'total_flos': 5.259924500788864e+18, 'train_loss': 2.2515898463395434, 'epoch': 2.999649081763949})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###############################################################################\n",
    "# Step 6: Load the Pre-trained Model\n",
    "###############################################################################\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "\n",
    "###############################################################################\n",
    "# Step 7: Define Metrics (WER)\n",
    "###############################################################################\n",
    "wer_metric = evaluate.load(\"wer\")\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    pred_ids = pred.predictions.argmax(-1)\n",
    "    # Decode predictions\n",
    "    pred_str = processor.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    # Decode labels\n",
    "    label_ids = pred.label_ids\n",
    "    # Replace -100 with pad token\n",
    "    label_ids = [[l for l in label if l != -100] for label in label_ids]\n",
    "    label_str = processor.batch_decode(label_ids, skip_special_tokens=True)\n",
    "\n",
    "    wer = wer_metric.compute(predictions=pred_str, references=label_str)\n",
    "    return {\"wer\": wer}\n",
    "\n",
    "###############################################################################\n",
    "# Step 8: Training Arguments\n",
    "###############################################################################\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./wav2vec2-finetuned-asr\",\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    gradient_accumulation_steps=2,\n",
    "    num_train_epochs=5,\n",
    "    eval_strategy=\"steps\", #evaluation_strategy\n",
    "    logging_steps=100,\n",
    "    save_steps=500,\n",
    "    learning_rate=1e-4,\n",
    "    warmup_steps=500,\n",
    "    fp16=True,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "###############################################################################\n",
    "# Step 9: Initialize Trainer\n",
    "###############################################################################\n",
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "# Create a data collator with padding\n",
    "data_collator = DataCollatorWithPadding(\n",
    "    tokenizer=processor.feature_extractor,  # Use the feature extractor as the tokenizer\n",
    "    padding=True,  # Ensure padding\n",
    "    return_tensors=\"pt\",  # Use PyTorch tensors\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    data_collator=data_collator,  # Add the data collator\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "###############################################################################\n",
    "# Step 10: Train the Model\n",
    "###############################################################################\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unsloth_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
